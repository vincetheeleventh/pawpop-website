import { NextRequest, NextResponse } from "next/server";
import { fal } from "@fal-ai/client";

// Force Node runtime on Vercel (not Edge)
export const runtime = "nodejs";

// Configure fal client
fal.config({
  credentials: process.env.FAL_KEY || process.env.HF_TOKEN
});

interface FluxTransformRequest {
  imageBuffer?: Buffer;
  imageUrl?: string;
  prompt: string;
  strength?: number;
  guidance_scale?: number;
  num_inference_steps?: number;
  seed?: number;
}

export async function POST(req: NextRequest) {
  console.log("ğŸ¨ /api/flux-transform POST request received");
  
  try {
    const contentType = req.headers.get('content-type');
    let body: FluxTransformRequest;
    let imageBuffer: Buffer | null = null;

    if (contentType?.includes('application/json')) {
      // JSON request with base64 image or URL
      const jsonBody = await req.json();
      body = jsonBody;
      
      if (jsonBody.imageBase64) {
        imageBuffer = Buffer.from(jsonBody.imageBase64, 'base64');
      }
    } else if (contentType?.includes('multipart/form-data')) {
      // Form data with file upload
      const formData = await req.formData();
      const file = formData.get('image') as File;
      const prompt = formData.get('prompt') as string;
      
      if (!file || !prompt) {
        return NextResponse.json({ error: "Image file and prompt are required" }, { status: 400 });
      }
      
      imageBuffer = Buffer.from(await file.arrayBuffer());
      body = {
        prompt,
        strength: parseFloat(formData.get('strength') as string) || 0.8,
        guidance_scale: parseFloat(formData.get('guidance_scale') as string) || 7.5,
        num_inference_steps: parseInt(formData.get('num_inference_steps') as string) || 28,
        seed: parseInt(formData.get('seed') as string) || Math.floor(Math.random() * 1000000)
      };
    } else {
      return NextResponse.json({ error: "Unsupported content type" }, { status: 400 });
    }

    console.log("ğŸ“‹ Request parameters:", {
      prompt: body.prompt,
      strength: body.strength,
      guidance_scale: body.guidance_scale,
      num_inference_steps: body.num_inference_steps,
      seed: body.seed,
      hasImageBuffer: !!imageBuffer,
      hasImageUrl: !!body.imageUrl
    });

    if (!body.prompt) {
      return NextResponse.json({ error: "Prompt is required" }, { status: 400 });
    }

    if (!imageBuffer && !body.imageUrl) {
      return NextResponse.json({ error: "Either image file or image URL is required" }, { status: 400 });
    }

    let imageUrl = body.imageUrl;

    // Upload image to fal storage if we have a buffer
    if (imageBuffer) {
      console.log("â˜ï¸ Uploading image to fal storage...");
      const imageFile = new File([new Uint8Array(imageBuffer)], 'input-image.png', { type: 'image/png' });
      imageUrl = await fal.storage.upload(imageFile);
      console.log("âœ… Image uploaded:", imageUrl);
    }

    // Run Flux transformation
    console.log("ğŸ¨ Running Flux LoRA transformation...");
    const result = await fal.subscribe('fal-ai/flux-kontext-lora', {
      input: {
        image_url: imageUrl!,
        prompt: body.prompt,
        guidance_scale: body.guidance_scale || 7.5,
        num_inference_steps: body.num_inference_steps || 28,
        seed: body.seed || Math.floor(Math.random() * 1000000)
      },
      logs: true,
      onQueueUpdate: (update) => {
        if (update.status === 'IN_PROGRESS') {
          console.log("â³ Flux processing:", update.status);
          if (update.logs) {
            update.logs.forEach(log => console.log("ğŸ“ Flux log:", log.message));
          }
        }
      }
    });

    console.log("âœ… Flux transformation complete!");
    
    if (!result.data || !result.data.images || !result.data.images[0]) {
      throw new Error("No image generated by Flux model");
    }

    const outputImageUrl = result.data.images[0].url;
    console.log("ğŸ–¼ï¸ Generated image URL:", outputImageUrl);

    // Download the result image and return as buffer
    console.log("ğŸ“¥ Downloading transformed image...");
    const imageResponse = await fetch(outputImageUrl);
    if (!imageResponse.ok) {
      throw new Error(`Failed to download image: ${imageResponse.status}`);
    }
    
    const resultBuffer = Buffer.from(await imageResponse.arrayBuffer());
    console.log("âœ… Image downloaded, size:", resultBuffer.length, "bytes");

    // Return the transformed image
    return new NextResponse(resultBuffer, {
      status: 200,
      headers: { 
        "Content-Type": "image/png",
        "Cache-Control": "no-store",
        "X-Generated-Image-URL": outputImageUrl
      },
    });

  } catch (error: any) {
    console.error("ğŸ’¥ Flux API Error:", error);
    console.error("ğŸ’¥ Error stack:", error?.stack);
    
    let errorMessage = error?.message || "Unknown error";
    let statusCode = 500;
    
    if (error?.message?.includes('credentials') || error?.message?.includes('unauthorized')) {
      errorMessage = "Invalid API credentials. Please check FAL_KEY or HF_TOKEN environment variable.";
      statusCode = 401;
    } else if (error?.message?.includes('quota') || error?.message?.includes('rate limit')) {
      errorMessage = "API quota exceeded or rate limited. Please try again later.";
      statusCode = 429;
    }
    
    return NextResponse.json({ 
      error: errorMessage,
      details: process.env.NODE_ENV === 'development' ? error?.stack : undefined
    }, { status: statusCode });
  }
}
